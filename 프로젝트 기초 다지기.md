---
title: 프로젝트 1_ 기초
date: 2020-08-20
update: 2020-08-20
tags:
  - 프로젝트

---











# 정규표현식

1번:

```python
[0-9a-zA-Z]*@+?[0-9a-zA-Z]+\.+.*
```



2번:

```python
[가힣]*[^<a-zA-Z/"=>\s\.]\.*
```

* \s : 공백 문자



```python
[가힣]*[^<a-zA-Z/"=>\s\.]*\.*
```

* \* 붙으면 안 됨



3-1번: 

```python
<span[^>]*>(.*)</span>
```

* \b : 백스페이스바를 눌렀을 때 효과가 나타나게 됩니다. 백스페이스바 : 엔터키 위에 [←] 이런 기호가 적힌 키.
* '()': ()안에 있는 문자를 그룹화

3-2번: 







# re

* `re.match()`: 가장 첫음절에 대하여 검사
* `re.serch()`: 문자열 **전체**에 대하여 검사. 처음에 찾은 것만 return
* `re.findall()`: re.serch()를 for문 돌리지 않아도 전체 문장에 대하여 전체 단어를 return





# scrapy

* `cd workspace`: 프로젝트 할 때 쓸 작업 폴더 하나 생성하고 이걸로 다시 경로 defalt 생성
* `scrapy startproject naver_crawler`: scrapy 작업 할 naver_crawler 폴더 생성
* `cd naver_crawler`: 다시 경로 defalt 생성
* `ls`: 현재 디렉토리 뭐 있나 확인
* `scrapy crawl naver`: vs code에서 수정한대로 터미널에서 실행해줄 때



* 순서

  1. settings.py 파일 수정

     ```python
     ROBOTSTXT_OBEY = False
     ```
  
     > False로 수정

  2. settings.py 파일 수정

     ```python
   ITEM_PIPELINES = {
        'naver_crawler.pipelines.NaverCrawlerPipeline': 300,
     }
     ```
  
     > 각주 처리 되어 있던 `ITEM_PIPELINES` 을 해제해준다.
  
  3. item.py 파일 수정

     ```python
   class NaverCrawlerItem(scrapy.Item):
         # define the fields for your item here like:
       	url = scrapy.Field()
         media = scrapy.Field()
         content = scrapy.Field()
     ```
  
     > 크롤시 dic 형태로 저장할 변수 정의해준다.
  
  4. item.py 파일에서 정의한 변수대로 naver_spider.py 파일에 작성 & 구체적인 tag(BeautifulSoup으로 크롤링 할 때처럼) 추가한다.
  
     ```python
         def parse(self, response):
             # dic 형태로 쓸 때,
           item = NaverCrawlerItem()
             item['url'] = response.url
             item['content'] = response.xpath("//div[@id='articleBodyContents']//text()").getall()
             item['media'] = response.xpath("//div[@class='press_logo']/a/img/@alt").get() 
             # // : 모든 tag 검색 
     
             yield item
     ```

     > 이때 `item = NaverCrawlerItem()` 사용하므로 naver_spider.py에서 
     
      >`from naver_crawler.items import NaverCrawlerItem` 써줘야 한다.
        > 
        >* yield: iterable하게 item들이 하나씩 쌓인다. 
        >   이 code는 링크가 하나지만, 여러 개의 링크를 사용할 경우에는 램 용량이 터지는 걸 방지하기 위해 하나씩 넣어줘서 하나씩 불러오는 yield를 사용한다. 비록 '하나씩 넣어줘서 하나씩 불러오는 yield를 사용' 하지만 하나만 출력되는 print와 달리 전부 다 불러온다.
      >   * 더 추가적인 개념은 https://wikidocs.net/16069 참고
  
  5. pipelines.py의 `class NaverCrawlerPipeline:`에서 크롤링해서 불러올 txt 들을 정의 및 전처리 해준다.
  
     * pipelines.py은 **저장 or 전처리**로 쓰는 듯하다. 
  
     ```python
     from scrapy.exporters import CsvItemExporter
     ```
  
     > csv로 저장하기 위해 pipelines.py에서 해당 패키지를 작성해준다.
  
     ```python
      class NaverCrawlerPipeline:
         def process_item(self, item, spider):
             with open('news.csv', 'wb') as f: # wb: 바이너리
                 exporter = CsvItemExporter(f, encoding="utf-8")
                 item['content'] = str(item['content']).replace("// flash 오류를 우회하기 위한 함수 추가", "")
                 exporter.export_item(item)
           return itemscrapy crawl naver
     ```
  
     > 위의 `.replace("// flash 오류를 우회하기 위한 함수 추가", "")`처럼 여기서 전처리 가능하다.
     >
     > 그런데 보통은 전처리 없이 raw data만을 가져와서 pandas에서 csv 읽고, 거기서 한꺼번에 전처리 하는 방식이 더 낫다.
     >
     > * 크롤링이 cpu를 많이 잡아먹기 때문.
  
  6. terminal에서 `scrapy crawl naver`작성 및 실행하여 크롤링 잘 되는지 확인한다.



# VSCODE

* 가상환경 빌드

  * 2.대의 Python Ver. 혹은 특정 version의 python이 필요할 때 사용

  ```python
  conda create --name mulcam python=3.6 anaconda
  ```

  



# git

* Working directory & Stage area & repository
  * working directory → stage area: `add .`
  * stage area → repository: `commit -m " "`

* commit 히스토리 확인

  ```python
  git log
  ```

* git add 특정 파일

  ```python
  git add naver_crawler/naver_crawler/settings.py
  ```

* 이전에 한 add 취소

  ```python
  git restore --staged naver_crawler/naver_crawler/settings.py
  ```

* git status로 취소 되었는지 확인

  ```python
  git status
  ```

* 파일의 변경된 부분 확인

  * vscode에서 code file 변경하고 명령자에서  입력

  ```python
  git log --patch
  ```

  or

  ```python
  git diff
  ```

  > --- : 변경 전 파일
  >
  > +++ : 변경 후 파일 등 변경된 파일, 내용을 보여준다.

  * 이후 자동으로 안 빠져나와지면 `q` 눌러서 파일 확인 빠져나오기

* git tracking 방지

  1. ignore 정의할 파일 생성 및 vscode로 바로 확인하기

  ``` python
  code .gitignore
  ```

  > 폴더 내에 .gitignore 파일이 생성되고, vscode로 켜짐

  2. 업로드 하지 않을 파일 확장자 명 작성

  ```python
  *.ini
  ```

  > gitignore 파일에 정의한 대로, .ini인 파일들 전부 업로드 하지 않게 됨

  3. git status로 Untracked file에 정의되어 나오는지 확인

  > (기존)
  >
  > Untracked files:
  >   (use "git add \<file>..." to include in what will be committed)
  >         env.ini
  >
  > (변경)
  >
  > 안 뜸.



## git branch



* branch 생성

  ```python
  git checkout -b header-fix 브랜치명
  ```

  or 

  ```python
  git checkout 브랜치명
  ```

> branch 옮길 때도 사용

* 어떤 브랜치에서 가져와 branch 생성

  1. 가져올 branch의 해쉬 확인

  ```python
  git log
  ```

  > commit 02dd0488bc4bcd5f2ee6c8f0b81c515d8144dca9 (HEAD -> header-fix, master, 02dd04)
  > Author: jynee <y.jynee@gmail.com>
  > Date:   Tue Aug 25 11:13:14 2020 +0900
  >
  > 이때 commit의 앞에서부터 6자리 복사

  2. commit 해쉬 복사한 것으로 branch 복사 및 붙여넣기

  ```python
  git checkout -b 02dd04
  ```

  3. git log로 잘 붙여넣어졌는지 확인

* branch 끼리 합치기

  * *git merge* > 

      1. 먼저 master branch로 switch

      ```python
      git checkout master
      ```

      2. master 브랜치랑 합칠 브랜치명 + merge

      ```python
      git merge 브랜치명
      ```

      > Auto-merging index.html
      >
      > **CONFLICT** (content): Merge conflict in index.html
      > Automatic merge failed; fix conflicts and then commit the result.
      >
      > index.html 끼리 충돌이 일어나버림
      >
      > 이때는 뭐가 더 맞는지 확인 후(VScode 상에서 확인 가능), 하나는 직접 지우면 된다. 

      3. git status로 수정되었는지 확인

  * *git rebase* >

    "merge와 달리 일련의 commit 정보를 만들어 붙인다. 충돌이 일어날 확률이 적다."

    ```python
    git pull -rebase origin master
    ```

  * (공통) branch 끼리 합치기 마지막 단계

    ```python
    git push --set-upstream origin 합쳐 만들 브랜치명
    ```

    





# AWS

## aws 협업 code

* 사용 예) 팀원이 가진 용량이 큰 dataset을 aws에 올려놓으면, 이걸 아래 code 사용해서 가져올 수 있음

  * 다만 해당 dataset 내용을 변경할 땐 원저자가 권한 변경 code를 진행해두었어야 함

* 다른 사람 폴더/파일 가져오기

  1. 위치 지정 

     `ln -s ‘source’ ‘destination’`

     * ‘destination’: 임의로 작성 가능. 내 aws 속에서 생성될 폴더명을 뜻함

      ```python
      ln -s /home/tutor/ronen ronen
      ```

  2. 가져올 파일/폴더 입력 `cp 폴더명/파일명(파일명은 확장자명까지) 내aws속에넣을이름`

     ```python
     cp attention.py  ../../ronen
     ```

* 파일/폴더 내용을 타인도 변경할 수 있게 하기 

  `chmod 777 폴더명 (or 파일명(파일명은 확장자명까지))`

  * 해당 폴더/파일 원작자가 변경해야 함

  * 해당 폴더/파일이 원작자의 변경이 필요하다는 걸 아는 방법

    ```python
    ll
    ```

    > **drwxr-xr-x** 6 lab multi 4096 Oct 13 13:42 mulcam/
    > **lrwxrwxrwx** 1 lab multi   18 Oct 13 13:54 ronen -> /home/tutor/ronen//

* 폴더 내용 보기

  ```python
  ls
  ```
  > attention.py          		      generate_pikle.py  				normalize.xlsx		  		TFIDF 			...

  ```python
  ls /home/tutor/
  ```

  > ronen  Untitled.ipynb

* 파일 내용 보기

  ```python
  cat /home/tutor/ronen/test.txt 
  ```

  > my name is ronen

* 현재 폴더 위치 변경 `cd 파일명`

  ```python
  cd jynee
  ```

  

